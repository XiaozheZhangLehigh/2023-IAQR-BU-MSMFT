{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaozhezhang/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime, timedelta\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import brier_score_loss, roc_curve, auc, log_loss\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| market_category | feature_name | id |\n",
    "|-----------------|--------------|----|\n",
    "| Bank            | bac          |  1 |\n",
    "| Bank            | citi         |  2 |\n",
    "| Commodity       | corn         |  3 |\n",
    "| Currency        | euro         |  4 |\n",
    "| Commodity       | gold         |  5 |\n",
    "| Inflation       | infl5y       |  6 |\n",
    "| Commodity       | iyr          |  7 |\n",
    "| Currency        | pound        |  8 |\n",
    "| Commodity       | silver       |  9 |\n",
    "| Commodity       | soybns       | 10 |\n",
    "| Equity          | sp12m        | 11 |\n",
    "| Equity          | sp6m         | 12 |\n",
    "| Commodity       | wheat        | 13 |\n",
    "| Currency        | yen          | 14 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return Model (Log Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mpd_sp500.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forwards filling\n",
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SP_adj_close</th>\n",
       "      <th>SP_lg_pr</th>\n",
       "      <th>SP_lg_ret(%)</th>\n",
       "      <th>VIX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-17</th>\n",
       "      <td>1480.939941</td>\n",
       "      <td>7.300432</td>\n",
       "      <td>0.597345</td>\n",
       "      <td>0.1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-24</th>\n",
       "      <td>1494.819946</td>\n",
       "      <td>7.309761</td>\n",
       "      <td>0.932878</td>\n",
       "      <td>0.1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-31</th>\n",
       "      <td>1498.109985</td>\n",
       "      <td>7.311960</td>\n",
       "      <td>0.219854</td>\n",
       "      <td>0.1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-07</th>\n",
       "      <td>1509.390015</td>\n",
       "      <td>7.319461</td>\n",
       "      <td>0.750130</td>\n",
       "      <td>0.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-14</th>\n",
       "      <td>1521.380005</td>\n",
       "      <td>7.327373</td>\n",
       "      <td>0.791222</td>\n",
       "      <td>0.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>4783.450195</td>\n",
       "      <td>8.472917</td>\n",
       "      <td>1.657668</td>\n",
       "      <td>0.1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17</th>\n",
       "      <td>4739.209961</td>\n",
       "      <td>8.463626</td>\n",
       "      <td>-0.929164</td>\n",
       "      <td>0.1479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>4868.549805</td>\n",
       "      <td>8.490551</td>\n",
       "      <td>2.692566</td>\n",
       "      <td>0.1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>4845.649902</td>\n",
       "      <td>8.485837</td>\n",
       "      <td>-0.471474</td>\n",
       "      <td>0.1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-07</th>\n",
       "      <td>4995.060059</td>\n",
       "      <td>8.516205</td>\n",
       "      <td>3.036806</td>\n",
       "      <td>0.1283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>577 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SP_adj_close  SP_lg_pr  SP_lg_ret(%)     VIX\n",
       "Date                                                    \n",
       "2013-01-17   1480.939941  7.300432      0.597345  0.1357\n",
       "2013-01-24   1494.819946  7.309761      0.932878  0.1269\n",
       "2013-01-31   1498.109985  7.311960      0.219854  0.1428\n",
       "2013-02-07   1509.390015  7.319461      0.750130  0.1350\n",
       "2013-02-14   1521.380005  7.327373      0.791222  0.1266\n",
       "...                  ...       ...           ...     ...\n",
       "2024-01-10   4783.450195  8.472917      1.657668  0.1269\n",
       "2024-01-17   4739.209961  8.463626     -0.929164  0.1479\n",
       "2024-01-24   4868.549805  8.490551      2.692566  0.1314\n",
       "2024-01-31   4845.649902  8.485837     -0.471474  0.1435\n",
       "2024-02-07   4995.060059  8.516205      3.036806  0.1283\n",
       "\n",
       "[577 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new df that extract the columns of SP_adj_close\tSP_lg_pr\tSP_lg_ret(%)\tVIX\n",
    "data = df[['SP_adj_close', 'SP_lg_pr', 'SP_lg_ret(%)', 'VIX']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep columns that have names containing f11 and f12 only\n",
    "df = df.filter(regex='f11|f12')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data to df merge on index\n",
    "df = pd.merge(df, data, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that has \"maturity_target\" , \"lg_change_decr\", and \"lg_change_incr\" in the column name; those are irrelevant for feature selection\n",
    "df = df[df.columns.drop(list(df.filter(regex='maturity_target')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='lg_change_decr')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='lg_change_incr')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='SP_adj_close')))]\n",
    "\n",
    "# drop SP_lg_ret(%)\t\n",
    "df = df.drop(['SP_lg_ret(%)'], axis=1)\n",
    "# df = df.drop(['SP_lg_pr'], axis=1)\n",
    "df = df.drop(['VIX'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n",
      "/var/folders/57/dq27lfpd1zb7kzzggckgkm2h0000gn/T/ipykernel_28857/2483780013.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{col}_lag{lag}'] = df[col].shift(lag)\n"
     ]
    }
   ],
   "source": [
    "# Generate lagged variables from f1_mu to SP_lg_pr\n",
    "lags = 6\n",
    "for lag in range(1, lags+1):\n",
    "    # for col in df.columns[df.columns.get_loc('f1_mu'):df.columns.get_loc('SP_lg_ret_vol')+1]:\n",
    "    # for col in df.columns[df.columns.get_loc('f1_mu'):df.columns.get_loc('VIX')+1]: \n",
    "    for col in df.columns[df.columns.get_loc('f11_mu'):df.columns.get_loc('SP_lg_pr')+1]: \n",
    "    #for col in df.columns[df.columns.get_loc('f11_mu'):df.columns.get_loc('SP_lg_ret(%)')+1]:    \n",
    "        df[f'{col}_lag{lag}'] = df[col].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(571, 133)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged = df.copy()\n",
    "# drop NA rows\n",
    "df_lagged = df_lagged.dropna()\n",
    "df_lagged.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f11_mu</th>\n",
       "      <th>f11_sd</th>\n",
       "      <th>f11_skew</th>\n",
       "      <th>f11_kurt</th>\n",
       "      <th>f11_p10</th>\n",
       "      <th>f11_p50</th>\n",
       "      <th>f11_p90</th>\n",
       "      <th>f11_prDec</th>\n",
       "      <th>f11_prInc</th>\n",
       "      <th>f12_mu</th>\n",
       "      <th>...</th>\n",
       "      <th>f12_mu_lag6</th>\n",
       "      <th>f12_sd_lag6</th>\n",
       "      <th>f12_skew_lag6</th>\n",
       "      <th>f12_kurt_lag6</th>\n",
       "      <th>f12_p10_lag6</th>\n",
       "      <th>f12_p50_lag6</th>\n",
       "      <th>f12_p90_lag6</th>\n",
       "      <th>f12_prDec_lag6</th>\n",
       "      <th>f12_prInc_lag6</th>\n",
       "      <th>SP_lg_pr_lag6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-28</th>\n",
       "      <td>-0.013760</td>\n",
       "      <td>0.165437</td>\n",
       "      <td>-1.064944</td>\n",
       "      <td>1.827118</td>\n",
       "      <td>-0.231609</td>\n",
       "      <td>0.014135</td>\n",
       "      <td>0.164019</td>\n",
       "      <td>0.123823</td>\n",
       "      <td>0.051886</td>\n",
       "      <td>-0.009874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005964</td>\n",
       "      <td>0.112827</td>\n",
       "      <td>-1.083202</td>\n",
       "      <td>1.904765</td>\n",
       "      <td>-0.154080</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>0.114733</td>\n",
       "      <td>0.063889</td>\n",
       "      <td>0.007340</td>\n",
       "      <td>7.300432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-07</th>\n",
       "      <td>-0.010876</td>\n",
       "      <td>0.156855</td>\n",
       "      <td>-1.125104</td>\n",
       "      <td>2.071839</td>\n",
       "      <td>-0.215251</td>\n",
       "      <td>0.015521</td>\n",
       "      <td>0.156367</td>\n",
       "      <td>0.111384</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>-0.007606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004666</td>\n",
       "      <td>0.101447</td>\n",
       "      <td>-1.053530</td>\n",
       "      <td>1.845878</td>\n",
       "      <td>-0.138036</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.104440</td>\n",
       "      <td>0.049584</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>7.309761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-14</th>\n",
       "      <td>-0.010876</td>\n",
       "      <td>0.156855</td>\n",
       "      <td>-1.125104</td>\n",
       "      <td>2.071839</td>\n",
       "      <td>-0.215251</td>\n",
       "      <td>0.015521</td>\n",
       "      <td>0.156367</td>\n",
       "      <td>0.111384</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>-0.007606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004666</td>\n",
       "      <td>0.101447</td>\n",
       "      <td>-1.053530</td>\n",
       "      <td>1.845878</td>\n",
       "      <td>-0.138036</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.104440</td>\n",
       "      <td>0.049584</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>7.311960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-21</th>\n",
       "      <td>-0.016487</td>\n",
       "      <td>0.168308</td>\n",
       "      <td>-1.137405</td>\n",
       "      <td>1.968257</td>\n",
       "      <td>-0.239122</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>0.162133</td>\n",
       "      <td>0.128493</td>\n",
       "      <td>0.047310</td>\n",
       "      <td>-0.006612</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003163</td>\n",
       "      <td>0.101097</td>\n",
       "      <td>-1.121946</td>\n",
       "      <td>2.196441</td>\n",
       "      <td>-0.133458</td>\n",
       "      <td>0.013368</td>\n",
       "      <td>0.105116</td>\n",
       "      <td>0.048146</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>7.319461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-28</th>\n",
       "      <td>-0.016487</td>\n",
       "      <td>0.168308</td>\n",
       "      <td>-1.137405</td>\n",
       "      <td>1.968257</td>\n",
       "      <td>-0.239122</td>\n",
       "      <td>0.013767</td>\n",
       "      <td>0.162133</td>\n",
       "      <td>0.128493</td>\n",
       "      <td>0.047310</td>\n",
       "      <td>-0.006612</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003163</td>\n",
       "      <td>0.101097</td>\n",
       "      <td>-1.121946</td>\n",
       "      <td>2.196441</td>\n",
       "      <td>-0.133458</td>\n",
       "      <td>0.013368</td>\n",
       "      <td>0.105116</td>\n",
       "      <td>0.048146</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>7.327373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-04</th>\n",
       "      <td>-0.017964</td>\n",
       "      <td>0.170384</td>\n",
       "      <td>-1.143630</td>\n",
       "      <td>2.112269</td>\n",
       "      <td>-0.241237</td>\n",
       "      <td>0.011775</td>\n",
       "      <td>0.162035</td>\n",
       "      <td>0.129501</td>\n",
       "      <td>0.051591</td>\n",
       "      <td>-0.005958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009874</td>\n",
       "      <td>0.112429</td>\n",
       "      <td>-1.038128</td>\n",
       "      <td>1.783160</td>\n",
       "      <td>-0.157649</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>0.111115</td>\n",
       "      <td>0.065920</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>7.314832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-11</th>\n",
       "      <td>-0.017964</td>\n",
       "      <td>0.170384</td>\n",
       "      <td>-1.143630</td>\n",
       "      <td>2.112269</td>\n",
       "      <td>-0.241237</td>\n",
       "      <td>0.011775</td>\n",
       "      <td>0.162035</td>\n",
       "      <td>0.129501</td>\n",
       "      <td>0.051591</td>\n",
       "      <td>-0.005958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009874</td>\n",
       "      <td>0.112429</td>\n",
       "      <td>-1.038128</td>\n",
       "      <td>1.783160</td>\n",
       "      <td>-0.157649</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>0.111115</td>\n",
       "      <td>0.065920</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>7.322960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-18</th>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.176993</td>\n",
       "      <td>-1.053618</td>\n",
       "      <td>1.869310</td>\n",
       "      <td>-0.249189</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>0.172501</td>\n",
       "      <td>0.135937</td>\n",
       "      <td>0.064454</td>\n",
       "      <td>-0.005473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007606</td>\n",
       "      <td>0.105005</td>\n",
       "      <td>-1.098673</td>\n",
       "      <td>2.081670</td>\n",
       "      <td>-0.143297</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.105231</td>\n",
       "      <td>0.055054</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>7.342300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-25</th>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.176993</td>\n",
       "      <td>-1.053618</td>\n",
       "      <td>1.869310</td>\n",
       "      <td>-0.249189</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>0.172501</td>\n",
       "      <td>0.135937</td>\n",
       "      <td>0.064454</td>\n",
       "      <td>-0.005473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007606</td>\n",
       "      <td>0.105005</td>\n",
       "      <td>-1.098673</td>\n",
       "      <td>2.081670</td>\n",
       "      <td>-0.143297</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.105231</td>\n",
       "      <td>0.055054</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>7.354509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-02</th>\n",
       "      <td>-0.015787</td>\n",
       "      <td>0.161705</td>\n",
       "      <td>-1.096729</td>\n",
       "      <td>1.986236</td>\n",
       "      <td>-0.227189</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.156766</td>\n",
       "      <td>0.120308</td>\n",
       "      <td>0.045228</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006612</td>\n",
       "      <td>0.107860</td>\n",
       "      <td>-1.102440</td>\n",
       "      <td>2.162107</td>\n",
       "      <td>-0.145138</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.109247</td>\n",
       "      <td>0.056902</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>7.343297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-09</th>\n",
       "      <td>-0.015787</td>\n",
       "      <td>0.161705</td>\n",
       "      <td>-1.096729</td>\n",
       "      <td>1.986236</td>\n",
       "      <td>-0.227189</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.156766</td>\n",
       "      <td>0.120308</td>\n",
       "      <td>0.045228</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006612</td>\n",
       "      <td>0.107860</td>\n",
       "      <td>-1.102440</td>\n",
       "      <td>2.162107</td>\n",
       "      <td>-0.145138</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>0.109247</td>\n",
       "      <td>0.056902</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>7.358315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-16</th>\n",
       "      <td>-0.022677</td>\n",
       "      <td>0.174182</td>\n",
       "      <td>-0.982589</td>\n",
       "      <td>1.755958</td>\n",
       "      <td>-0.248891</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.167623</td>\n",
       "      <td>0.136680</td>\n",
       "      <td>0.061060</td>\n",
       "      <td>-0.010792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005958</td>\n",
       "      <td>0.107058</td>\n",
       "      <td>-1.083615</td>\n",
       "      <td>2.067795</td>\n",
       "      <td>-0.144257</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>0.109247</td>\n",
       "      <td>0.055826</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>7.352428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-23</th>\n",
       "      <td>-0.022677</td>\n",
       "      <td>0.174182</td>\n",
       "      <td>-0.982589</td>\n",
       "      <td>1.755958</td>\n",
       "      <td>-0.248891</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.167623</td>\n",
       "      <td>0.136680</td>\n",
       "      <td>0.061060</td>\n",
       "      <td>-0.010792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005958</td>\n",
       "      <td>0.107058</td>\n",
       "      <td>-1.083615</td>\n",
       "      <td>2.067795</td>\n",
       "      <td>-0.144257</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>0.109247</td>\n",
       "      <td>0.055826</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>7.373607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-30</th>\n",
       "      <td>-0.021866</td>\n",
       "      <td>0.177121</td>\n",
       "      <td>-1.022351</td>\n",
       "      <td>1.860562</td>\n",
       "      <td>-0.251731</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.169945</td>\n",
       "      <td>0.138207</td>\n",
       "      <td>0.063189</td>\n",
       "      <td>-0.009545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005473</td>\n",
       "      <td>0.115250</td>\n",
       "      <td>-1.039321</td>\n",
       "      <td>1.977262</td>\n",
       "      <td>-0.154064</td>\n",
       "      <td>0.011598</td>\n",
       "      <td>0.119365</td>\n",
       "      <td>0.063720</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>7.340583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-06</th>\n",
       "      <td>-0.021866</td>\n",
       "      <td>0.177121</td>\n",
       "      <td>-1.022351</td>\n",
       "      <td>1.860562</td>\n",
       "      <td>-0.251731</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.169945</td>\n",
       "      <td>0.138207</td>\n",
       "      <td>0.063189</td>\n",
       "      <td>-0.009545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005473</td>\n",
       "      <td>0.115250</td>\n",
       "      <td>-1.039321</td>\n",
       "      <td>1.977262</td>\n",
       "      <td>-0.154064</td>\n",
       "      <td>0.011598</td>\n",
       "      <td>0.119365</td>\n",
       "      <td>0.063720</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>7.368441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-13</th>\n",
       "      <td>-0.021235</td>\n",
       "      <td>0.187769</td>\n",
       "      <td>-1.167774</td>\n",
       "      <td>2.137143</td>\n",
       "      <td>-0.269413</td>\n",
       "      <td>0.012762</td>\n",
       "      <td>0.174777</td>\n",
       "      <td>0.146378</td>\n",
       "      <td>0.068007</td>\n",
       "      <td>-0.008064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.101177</td>\n",
       "      <td>-1.021220</td>\n",
       "      <td>2.003773</td>\n",
       "      <td>-0.133812</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.105914</td>\n",
       "      <td>0.047172</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>7.376252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-20</th>\n",
       "      <td>-0.021235</td>\n",
       "      <td>0.187769</td>\n",
       "      <td>-1.167774</td>\n",
       "      <td>2.137143</td>\n",
       "      <td>-0.269413</td>\n",
       "      <td>0.012762</td>\n",
       "      <td>0.174777</td>\n",
       "      <td>0.146378</td>\n",
       "      <td>0.068007</td>\n",
       "      <td>-0.008064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.101177</td>\n",
       "      <td>-1.021220</td>\n",
       "      <td>2.003773</td>\n",
       "      <td>-0.133812</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.105914</td>\n",
       "      <td>0.047172</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>7.394290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-27</th>\n",
       "      <td>-0.017449</td>\n",
       "      <td>0.191979</td>\n",
       "      <td>-1.181058</td>\n",
       "      <td>2.107294</td>\n",
       "      <td>-0.270551</td>\n",
       "      <td>0.018342</td>\n",
       "      <td>0.184230</td>\n",
       "      <td>0.147936</td>\n",
       "      <td>0.077267</td>\n",
       "      <td>-0.005913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010792</td>\n",
       "      <td>0.110898</td>\n",
       "      <td>-0.855946</td>\n",
       "      <td>1.564900</td>\n",
       "      <td>-0.152414</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.113800</td>\n",
       "      <td>0.059805</td>\n",
       "      <td>0.010901</td>\n",
       "      <td>7.408815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-04</th>\n",
       "      <td>-0.017449</td>\n",
       "      <td>0.191979</td>\n",
       "      <td>-1.181058</td>\n",
       "      <td>2.107294</td>\n",
       "      <td>-0.270551</td>\n",
       "      <td>0.018342</td>\n",
       "      <td>0.184230</td>\n",
       "      <td>0.147936</td>\n",
       "      <td>0.077267</td>\n",
       "      <td>-0.005913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010792</td>\n",
       "      <td>0.110898</td>\n",
       "      <td>-0.855946</td>\n",
       "      <td>1.564900</td>\n",
       "      <td>-0.152414</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.113800</td>\n",
       "      <td>0.059805</td>\n",
       "      <td>0.010901</td>\n",
       "      <td>7.408840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-11</th>\n",
       "      <td>-0.014788</td>\n",
       "      <td>0.169829</td>\n",
       "      <td>-1.183246</td>\n",
       "      <td>2.218823</td>\n",
       "      <td>-0.236500</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.163930</td>\n",
       "      <td>0.126412</td>\n",
       "      <td>0.050835</td>\n",
       "      <td>-0.006534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009545</td>\n",
       "      <td>0.114667</td>\n",
       "      <td>-0.894642</td>\n",
       "      <td>1.568278</td>\n",
       "      <td>-0.157133</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.118444</td>\n",
       "      <td>0.063932</td>\n",
       "      <td>0.011926</td>\n",
       "      <td>7.411200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              f11_mu    f11_sd  f11_skew  f11_kurt   f11_p10   f11_p50  \\\n",
       "Date                                                                     \n",
       "2013-02-28 -0.013760  0.165437 -1.064944  1.827118 -0.231609  0.014135   \n",
       "2013-03-07 -0.010876  0.156855 -1.125104  2.071839 -0.215251  0.015521   \n",
       "2013-03-14 -0.010876  0.156855 -1.125104  2.071839 -0.215251  0.015521   \n",
       "2013-03-21 -0.016487  0.168308 -1.137405  1.968257 -0.239122  0.013767   \n",
       "2013-03-28 -0.016487  0.168308 -1.137405  1.968257 -0.239122  0.013767   \n",
       "2013-04-04 -0.017964  0.170384 -1.143630  2.112269 -0.241237  0.011775   \n",
       "2013-04-11 -0.017964  0.170384 -1.143630  2.112269 -0.241237  0.011775   \n",
       "2013-04-18 -0.018118  0.176993 -1.053618  1.869310 -0.249189  0.010181   \n",
       "2013-04-25 -0.018118  0.176993 -1.053618  1.869310 -0.249189  0.010181   \n",
       "2013-05-02 -0.015787  0.161705 -1.096729  1.986236 -0.227189  0.011341   \n",
       "2013-05-09 -0.015787  0.161705 -1.096729  1.986236 -0.227189  0.011341   \n",
       "2013-05-16 -0.022677  0.174182 -0.982589  1.755958 -0.248891  0.002571   \n",
       "2013-05-23 -0.022677  0.174182 -0.982589  1.755958 -0.248891  0.002571   \n",
       "2013-05-30 -0.021866  0.177121 -1.022351  1.860562 -0.251731  0.004784   \n",
       "2013-06-06 -0.021866  0.177121 -1.022351  1.860562 -0.251731  0.004784   \n",
       "2013-06-13 -0.021235  0.187769 -1.167774  2.137143 -0.269413  0.012762   \n",
       "2013-06-20 -0.021235  0.187769 -1.167774  2.137143 -0.269413  0.012762   \n",
       "2013-06-27 -0.017449  0.191979 -1.181058  2.107294 -0.270551  0.018342   \n",
       "2013-07-04 -0.017449  0.191979 -1.181058  2.107294 -0.270551  0.018342   \n",
       "2013-07-11 -0.014788  0.169829 -1.183246  2.218823 -0.236500  0.016000   \n",
       "\n",
       "             f11_p90  f11_prDec  f11_prInc    f12_mu  ...  f12_mu_lag6  \\\n",
       "Date                                                  ...                \n",
       "2013-02-28  0.164019   0.123823   0.051886 -0.009874  ...    -0.005964   \n",
       "2013-03-07  0.156367   0.111384   0.041900 -0.007606  ...    -0.004666   \n",
       "2013-03-14  0.156367   0.111384   0.041900 -0.007606  ...    -0.004666   \n",
       "2013-03-21  0.162133   0.128493   0.047310 -0.006612  ...    -0.003163   \n",
       "2013-03-28  0.162133   0.128493   0.047310 -0.006612  ...    -0.003163   \n",
       "2013-04-04  0.162035   0.129501   0.051591 -0.005958  ...    -0.009874   \n",
       "2013-04-11  0.162035   0.129501   0.051591 -0.005958  ...    -0.009874   \n",
       "2013-04-18  0.172501   0.135937   0.064454 -0.005473  ...    -0.007606   \n",
       "2013-04-25  0.172501   0.135937   0.064454 -0.005473  ...    -0.007606   \n",
       "2013-05-02  0.156766   0.120308   0.045228 -0.004296  ...    -0.006612   \n",
       "2013-05-09  0.156766   0.120308   0.045228 -0.004296  ...    -0.006612   \n",
       "2013-05-16  0.167623   0.136680   0.061060 -0.010792  ...    -0.005958   \n",
       "2013-05-23  0.167623   0.136680   0.061060 -0.010792  ...    -0.005958   \n",
       "2013-05-30  0.169945   0.138207   0.063189 -0.009545  ...    -0.005473   \n",
       "2013-06-06  0.169945   0.138207   0.063189 -0.009545  ...    -0.005473   \n",
       "2013-06-13  0.174777   0.146378   0.068007 -0.008064  ...    -0.004296   \n",
       "2013-06-20  0.174777   0.146378   0.068007 -0.008064  ...    -0.004296   \n",
       "2013-06-27  0.184230   0.147936   0.077267 -0.005913  ...    -0.010792   \n",
       "2013-07-04  0.184230   0.147936   0.077267 -0.005913  ...    -0.010792   \n",
       "2013-07-11  0.163930   0.126412   0.050835 -0.006534  ...    -0.009545   \n",
       "\n",
       "            f12_sd_lag6  f12_skew_lag6  f12_kurt_lag6  f12_p10_lag6  \\\n",
       "Date                                                                  \n",
       "2013-02-28     0.112827      -1.083202       1.904765     -0.154080   \n",
       "2013-03-07     0.101447      -1.053530       1.845878     -0.138036   \n",
       "2013-03-14     0.101447      -1.053530       1.845878     -0.138036   \n",
       "2013-03-21     0.101097      -1.121946       2.196441     -0.133458   \n",
       "2013-03-28     0.101097      -1.121946       2.196441     -0.133458   \n",
       "2013-04-04     0.112429      -1.038128       1.783160     -0.157649   \n",
       "2013-04-11     0.112429      -1.038128       1.783160     -0.157649   \n",
       "2013-04-18     0.105005      -1.098673       2.081670     -0.143297   \n",
       "2013-04-25     0.105005      -1.098673       2.081670     -0.143297   \n",
       "2013-05-02     0.107860      -1.102440       2.162107     -0.145138   \n",
       "2013-05-09     0.107860      -1.102440       2.162107     -0.145138   \n",
       "2013-05-16     0.107058      -1.083615       2.067795     -0.144257   \n",
       "2013-05-23     0.107058      -1.083615       2.067795     -0.144257   \n",
       "2013-05-30     0.115250      -1.039321       1.977262     -0.154064   \n",
       "2013-06-06     0.115250      -1.039321       1.977262     -0.154064   \n",
       "2013-06-13     0.101177      -1.021220       2.003773     -0.133812   \n",
       "2013-06-20     0.101177      -1.021220       2.003773     -0.133812   \n",
       "2013-06-27     0.110898      -0.855946       1.564900     -0.152414   \n",
       "2013-07-04     0.110898      -0.855946       1.564900     -0.152414   \n",
       "2013-07-11     0.114667      -0.894642       1.568278     -0.157133   \n",
       "\n",
       "            f12_p50_lag6  f12_p90_lag6  f12_prDec_lag6  f12_prInc_lag6  \\\n",
       "Date                                                                     \n",
       "2013-02-28      0.013135      0.114733        0.063889        0.007340   \n",
       "2013-03-07      0.012280      0.104440        0.049584        0.003538   \n",
       "2013-03-14      0.012280      0.104440        0.049584        0.003538   \n",
       "2013-03-21      0.013368      0.105116        0.048146        0.003592   \n",
       "2013-03-28      0.013368      0.105116        0.048146        0.003592   \n",
       "2013-04-04      0.008259      0.111115        0.065920        0.007199   \n",
       "2013-04-11      0.008259      0.111115        0.065920        0.007199   \n",
       "2013-04-18      0.009019      0.105231        0.055054        0.004169   \n",
       "2013-04-25      0.009019      0.105231        0.055054        0.004169   \n",
       "2013-05-02      0.010250      0.109247        0.056902        0.005709   \n",
       "2013-05-09      0.010250      0.109247        0.056902        0.005709   \n",
       "2013-05-16      0.011101      0.109247        0.055826        0.005746   \n",
       "2013-05-23      0.011101      0.109247        0.055826        0.005746   \n",
       "2013-05-30      0.011598      0.119365        0.063720        0.011192   \n",
       "2013-06-06      0.011598      0.119365        0.063720        0.011192   \n",
       "2013-06-13      0.010151      0.105914        0.047172        0.005085   \n",
       "2013-06-20      0.010151      0.105914        0.047172        0.005085   \n",
       "2013-06-27      0.002464      0.113800        0.059805        0.010901   \n",
       "2013-07-04      0.002464      0.113800        0.059805        0.010901   \n",
       "2013-07-11      0.005079      0.118444        0.063932        0.011926   \n",
       "\n",
       "            SP_lg_pr_lag6  \n",
       "Date                       \n",
       "2013-02-28       7.300432  \n",
       "2013-03-07       7.309761  \n",
       "2013-03-14       7.311960  \n",
       "2013-03-21       7.319461  \n",
       "2013-03-28       7.327373  \n",
       "2013-04-04       7.314832  \n",
       "2013-04-11       7.322960  \n",
       "2013-04-18       7.342300  \n",
       "2013-04-25       7.354509  \n",
       "2013-05-02       7.343297  \n",
       "2013-05-09       7.358315  \n",
       "2013-05-16       7.352428  \n",
       "2013-05-23       7.373607  \n",
       "2013-05-30       7.340583  \n",
       "2013-06-06       7.368441  \n",
       "2013-06-13       7.376252  \n",
       "2013-06-20       7.394290  \n",
       "2013-06-27       7.408815  \n",
       "2013-07-04       7.408840  \n",
       "2013-07-11       7.411200  \n",
       "\n",
       "[20 rows x 133 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lagged.to_csv('mpd_sp500_lagged_log_price.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target variable\n",
    "start_colunm = df_lagged.columns.get_loc('f11_mu_lag1')\n",
    "# end_column = df_lagged.columns.get_loc('VIX_lag6')\n",
    "end_column = df_lagged.columns.get_loc('SP_lg_pr_lag6')\n",
    "#end_column = df_lagged.columns.get_loc('SP_lg_ret(%)_lag6')\n",
    "\n",
    "column_index = list(range(start_colunm, end_column+1))\n",
    "\n",
    "X = df_lagged.iloc[:, column_index]\n",
    "# y = df_lagged['SP_lg_ret(%)'] \n",
    "y = df_lagged['SP_lg_pr'] \n",
    "\n",
    "split_index = int(len(X)*0.75)\n",
    "X_train = X[:split_index]\n",
    "X_test = X[split_index:]\n",
    "y_train = y[:split_index]\n",
    "y_test = y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((428, 114), (143, 114), (428,), (143,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(cv=10, max_iter=10000, random_state=12345, selection=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(cv=10, max_iter=10000, random_state=12345, selection=&#x27;random&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(cv=10, max_iter=10000, random_state=12345, selection='random')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run a lasso regression to select features\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lassoCV = LassoCV(cv=10, random_state=12345, max_iter=10000, tol=0.0001, selection='random')\n",
    "lassoCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Sample R^2:  0.99314\n",
      "\n",
      "Out of Sample R^2:  0.87785\n",
      "\n",
      "Number of features selected:  12\n",
      "                   coef\n",
      "f11_kurt_lag1 -0.005614\n",
      "f12_kurt_lag1  0.007945\n",
      "SP_lg_pr_lag1  0.959054\n",
      "f11_kurt_lag2  0.001958\n",
      "SP_lg_pr_lag2  0.002003\n",
      "f11_p10_lag4  -0.035641\n",
      "f12_kurt_lag4 -0.005773\n",
      "f11_kurt_lag5  0.007417\n",
      "f12_kurt_lag5 -0.002573\n",
      "f11_kurt_lag6 -0.004551\n",
      "f12_kurt_lag6 -0.000052\n",
      "SP_lg_pr_lag6  0.033627\n",
      "\n",
      "Out of Sample Test set evaluation:\n",
      "MSE: 0.00060, RMSE: 0.02458, MAE: 0.01869, MAPE: 0.22389\n"
     ]
    }
   ],
   "source": [
    "print(\"In Sample R^2: \", f'{lassoCV.score(X_train, y_train):.5f}')\n",
    "print()\n",
    "print(\"Out of Sample R^2: \", f'{lassoCV.score(X_test, y_test):.5f}')\n",
    "print()\n",
    "# lasso coefficients with corresponding feature names\n",
    "lasso_coef = pd.DataFrame(lassoCV.coef_, index=X.columns, columns=['coef'])\n",
    "lasso_coef = lasso_coef[lasso_coef.coef != 0]\n",
    "\n",
    "print(\"Number of features selected: \", len(lasso_coef))\n",
    "print(lasso_coef)\n",
    "\n",
    "print()\n",
    "# show the predicted value\n",
    "lass_y_pred = lassoCV.predict(X_test)\n",
    "# calculate the MSE, RMSE, and MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "lass_mse = mean_squared_error(y_test, lass_y_pred)\n",
    "lass_rmse = np.sqrt(lass_mse)\n",
    "lass_mae = mean_absolute_error(y_test, lass_y_pred)\n",
    "lass_mape = np.mean(np.abs((y_test - lass_y_pred) / y_test)) * 100\n",
    "\n",
    "print('Out of Sample Test set evaluation:')\n",
    "print(f'MSE: {lass_mse:.5f}, RMSE: {lass_rmse:.5f}, MAE: {lass_mae:.5f}, MAPE: {lass_mape:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applied StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a lasso regression to select features\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(cv=10, max_iter=10000, random_state=12345, selection=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(cv=10, max_iter=10000, random_state=12345, selection=&#x27;random&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(cv=10, max_iter=10000, random_state=12345, selection='random')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoCV2 = LassoCV(cv=10, random_state=12345, max_iter=10000, tol=0.0001, selection='random')\n",
    "lassoCV2.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Sample R^2:  0.99301\n",
      "\n",
      "Out of Sample R^2:  0.87591\n",
      "\n",
      "Number of features selected:  7\n",
      "                    coef\n",
      "f12_mu_lag1     0.000848\n",
      "SP_lg_pr_lag1   0.213467\n",
      "SP_lg_pr_lag2   0.017935\n",
      "f12_p50_lag3    0.000948\n",
      "f12_prInc_lag3  0.003012\n",
      "f11_prInc_lag4  0.000592\n",
      "f12_prInc_lag4  0.001080\n",
      "\n",
      "Test set evaluation:\n",
      "MSE: 0.00061, RMSE: 0.02478, MAE: 0.01900, MAPE: 0.22764\n"
     ]
    }
   ],
   "source": [
    "print(\"In Sample R^2: \", f'{lassoCV2.score(X_train_scaled, y_train):.5f}')\n",
    "print()\n",
    "print(\"Out of Sample R^2: \", f'{lassoCV2.score(X_test_scaled, y_test):.5f}')\n",
    "print()\n",
    "\n",
    "# lasso coefficients with corresponding feature names\n",
    "lasso_coef = pd.DataFrame(lassoCV2.coef_, index=X.columns, columns=['coef'])\n",
    "lasso_coef = lasso_coef[lasso_coef.coef != 0]\n",
    "\n",
    "print(\"Number of features selected: \", len(lasso_coef))\n",
    "print(lasso_coef)\n",
    "\n",
    "print()\n",
    "# show the predicted value\n",
    "lassCV2_y_pred = lassoCV2.predict(X_test_scaled)\n",
    "# calculate the MSE, RMSE, and MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "lass_mse = mean_squared_error(y_test, lassCV2_y_pred)\n",
    "lass_rmse = np.sqrt(lass_mse)\n",
    "lass_mae = mean_absolute_error(y_test, lassCV2_y_pred)\n",
    "lass_mape = np.mean(np.abs((y_test - lassCV2_y_pred) / y_test)) * 100\n",
    "\n",
    "print('Test set evaluation:')\n",
    "print(f'MSE: {lass_mse:.5f}, RMSE: {lass_rmse:.5f}, MAE: {lass_mae:.5f}, MAPE: {lass_mape:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Log Price Lasso Regression, unscalered has better result (LassoCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Initialize the LassoCV model\n",
    "lassoCV_rolling = LassoCV(cv=10, random_state=12345, max_iter=10000, tol=0.0001, selection='random')\n",
    "\n",
    "# Initialize an empty array to store predictions\n",
    "predictions = []\n",
    "\n",
    "# initialize X_train_rolling and y_train_rolling\n",
    "X_train_rolling = X_train.copy()\n",
    "y_train_rolling = y_train.copy()\n",
    "\n",
    "# Iterate through the dataset\n",
    "for i in range(len(X_test)):\n",
    "    # Convert X_train back to a DataFrame\n",
    "    \n",
    "    \n",
    "    # Add the new observation to X_train_df and y_train\n",
    "    X_train_rolling = pd.concat([X_train_rolling, X_test.iloc[[i]]])\n",
    "    y_train_rolling = np.append(y_train_rolling, y_test[i])\n",
    "    \n",
    "    # Fit the LassoCV model with the updated training data\n",
    "    lassoCV_rolling.fit(X_train_rolling, y_train_rolling)\n",
    "    \n",
    "    # Predict the next day's y\n",
    "    next_day_prediction = lassoCV_rolling.predict(X_test.iloc[[i]])\n",
    "    \n",
    "    # Store the prediction in the array\n",
    "    predictions.append(next_day_prediction)\n",
    "    \n",
    "    # Print or store the prediction for the next day\n",
    "    # print(f\"Day {i+1} Prediction: {next_day_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([8.306013]),\n",
       " array([8.3238329]),\n",
       " array([8.34139833]),\n",
       " array([8.35053609]),\n",
       " array([8.34646105]),\n",
       " array([8.3476247]),\n",
       " array([8.3552422]),\n",
       " array([8.36495126]),\n",
       " array([8.38134448]),\n",
       " array([8.38282365]),\n",
       " array([8.38227696]),\n",
       " array([8.39274607]),\n",
       " array([8.39126406]),\n",
       " array([8.39501053]),\n",
       " array([8.38586268]),\n",
       " array([8.40672105]),\n",
       " array([8.41797845]),\n",
       " array([8.41659119]),\n",
       " array([8.40581247]),\n",
       " array([8.38915887]),\n",
       " array([8.37918392]),\n",
       " array([8.38012182]),\n",
       " array([8.38129619]),\n",
       " array([8.41981475]),\n",
       " array([8.42290977]),\n",
       " array([8.45068258]),\n",
       " array([8.44105975]),\n",
       " array([8.45214018]),\n",
       " array([8.4520785]),\n",
       " array([8.41967058]),\n",
       " array([8.45267612]),\n",
       " array([8.46146915]),\n",
       " array([8.46103093]),\n",
       " array([8.4731896]),\n",
       " array([8.4591416]),\n",
       " array([8.45994144]),\n",
       " array([8.41461679]),\n",
       " array([8.38346917]),\n",
       " array([8.43046733]),\n",
       " array([8.43547175]),\n",
       " array([8.40768688]),\n",
       " array([8.35027481]),\n",
       " array([8.38643094]),\n",
       " array([8.36075574]),\n",
       " array([8.38408948]),\n",
       " array([8.40163833]),\n",
       " array([8.43496121]),\n",
       " array([8.40991617]),\n",
       " array([8.40336031]),\n",
       " array([8.39849463]),\n",
       " array([8.34319056]),\n",
       " array([8.36608983]),\n",
       " array([8.28626526]),\n",
       " array([8.27627719]),\n",
       " array([8.28381508]),\n",
       " array([8.32198306]),\n",
       " array([8.31302409]),\n",
       " array([8.24447735]),\n",
       " array([8.23434051]),\n",
       " array([8.24801754]),\n",
       " array([8.25578399]),\n",
       " array([8.24866999]),\n",
       " array([8.2790693]),\n",
       " array([8.29855293]),\n",
       " array([8.33003048]),\n",
       " array([8.34540161]),\n",
       " array([8.35994639]),\n",
       " array([8.33119783]),\n",
       " array([8.28625972]),\n",
       " array([8.28905217]),\n",
       " array([8.28197928]),\n",
       " array([8.24577425]),\n",
       " array([8.22535527]),\n",
       " array([8.23927968]),\n",
       " array([8.19140139]),\n",
       " array([8.21293172]),\n",
       " array([8.2473072]),\n",
       " array([8.23125757]),\n",
       " array([8.22957815]),\n",
       " array([8.27937809]),\n",
       " array([8.30314202]),\n",
       " array([8.31511289]),\n",
       " array([8.28086377]),\n",
       " array([8.29162137]),\n",
       " array([8.26447615]),\n",
       " array([8.24315488]),\n",
       " array([8.25519783]),\n",
       " array([8.28443617]),\n",
       " array([8.28157199]),\n",
       " array([8.29994899]),\n",
       " array([8.32463233]),\n",
       " array([8.32651415]),\n",
       " array([8.32915453]),\n",
       " array([8.29570598]),\n",
       " array([8.28750554]),\n",
       " array([8.27367198]),\n",
       " array([8.27710585]),\n",
       " array([8.29811582]),\n",
       " array([8.30871236]),\n",
       " array([8.31941816]),\n",
       " array([8.32791751]),\n",
       " array([8.31125356]),\n",
       " array([8.31712811]),\n",
       " array([8.32515035]),\n",
       " array([8.33625222]),\n",
       " array([8.32460836]),\n",
       " array([8.333907]),\n",
       " array([8.35329726]),\n",
       " array([8.37348272]),\n",
       " array([8.37389768]),\n",
       " array([8.38129264]),\n",
       " array([8.39192672]),\n",
       " array([8.40281749]),\n",
       " array([8.417929]),\n",
       " array([8.42529845]),\n",
       " array([8.41062688]),\n",
       " array([8.40403166]),\n",
       " array([8.38731302]),\n",
       " array([8.39667591]),\n",
       " array([8.40843253]),\n",
       " array([8.40373162]),\n",
       " array([8.39477112]),\n",
       " array([8.40240402]),\n",
       " array([8.3856565]),\n",
       " array([8.36234822]),\n",
       " array([8.3583963]),\n",
       " array([8.38099852]),\n",
       " array([8.36993738]),\n",
       " array([8.34302459]),\n",
       " array([8.35065938]),\n",
       " array([8.38082433]),\n",
       " array([8.40994218]),\n",
       " array([8.42215371]),\n",
       " array([8.42152542]),\n",
       " array([8.42110787]),\n",
       " array([8.45109872]),\n",
       " array([8.45541141]),\n",
       " array([8.47014974]),\n",
       " array([8.4578341]),\n",
       " array([8.47315352]),\n",
       " array([8.46437969]),\n",
       " array([8.48790696]),\n",
       " array([8.48590988])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the predictions\n",
    "Rolling_y_pred= np.array(predictions).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of Sample Test set evaluation:\n",
      "MSE: 0.00057, RMSE: 0.02381, MAE: 0.01818, MAPE: 0.21783\n"
     ]
    }
   ],
   "source": [
    "# calculate the MSE, RMSE, and MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "lass_mse = mean_squared_error(y_test, Rolling_y_pred)\n",
    "lass_rmse = np.sqrt(lass_mse)\n",
    "lass_mae = mean_absolute_error(y_test, Rolling_y_pred)\n",
    "lass_mape = np.mean(np.abs((y_test - Rolling_y_pred) / y_test)) * 100\n",
    "\n",
    "print('Out of Sample Test set evaluation:')\n",
    "print(f'MSE: {lass_mse:.5f}, RMSE: {lass_rmse:.5f}, MAE: {lass_mae:.5f}, MAPE: {lass_mape:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "Rolling_y_pred = pd.DataFrame(lassCV2_y_pred)\n",
    "# rename to Predicted_SP_lg_pr\n",
    "Rolling_y_pred.columns = ['Predicted_SP_lg_pr']\n",
    "Rolling_y_pred.to_csv('Rolling_Predicted_SP_lg_pr.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
